
@article{kirasich_random_2018,
	title = {Random {Forest} vs {Logistic} {Regression}: {Binary} {Classification} for {Heterogeneous} {Datasets}},
	volume = {1},
	shorttitle = {Random {Forest} vs {Logistic} {Regression}},
	url = {https://scholar.smu.edu/datasciencereview/vol1/iss3/9},
	number = {3},
	journal = {SMU Data Science Review},
	author = {Kirasich, Kaitlin and Smith, Trace and Sadler, Bivin},
	month = aug,
	year = {2018},
	file = {"Random Forest vs Logistic Regression for Binary Classification" by Kaitlin Kirasich, Trace Smith et al.:C\:\\Users\\danie\\Zotero\\storage\\MH6PI2WX\\9.html:text/html;Kirasich et al. - 2018 - Random Forest vs Logistic Regression Binary Class.pdf:C\:\\Users\\danie\\Zotero\\storage\\W555PLCY\\Kirasich et al. - 2018 - Random Forest vs Logistic Regression Binary Class.pdf:application/pdf},
}

@inproceedings{ali_classification_2019,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {Classification of {Heterogeneous} {Data} {Based} on {Data} {Type} {Impact} on {Similarity}},
	isbn = {978-3-319-97982-3},
	doi = {10.1007/978-3-319-97982-3_21},
	abstract = {Real-world datasets are increasingly heterogeneous, showing a mixture of numerical, categorical and other feature types. The main challenge for mining heterogeneous datasets is how to deal with heterogeneity present in the dataset records. Although some existing classifiers (such as decision trees) can handle heterogeneous data in specific circumstances, the performance of such models may be still improved, because heterogeneity involves specific adjustments to similarity measurements and calculations. Moreover, heterogeneous data is still treated inconsistently and in ad-hoc manner. In this paper, we study the problem of heterogeneous data classification: our purpose is to use heterogeneity as a positive feature of the data classification effort by using consistently the similarity between data objects. We address the heterogeneity issue by studying the impact of mixing data types in the calculation of data objectsâ€™ similarity. To reach our goal, we propose an algorithm to divide the initial data records based on pairwise similarity for classification subtasks with the aim to increase the quality of the data subsets and apply specialized classifier models on them. The performance of the proposed approach is evaluated on 10 publicly available heterogeneous data sets. The results show that the models achieve better performance for heterogeneous datasets when using the proposed similarity process.},
	language = {en},
	booktitle = {Advances in {Computational} {Intelligence} {Systems}},
	publisher = {Springer International Publishing},
	author = {Ali, Najat and Neagu, Daniel and Trundle, Paul},
	editor = {Lotfi, Ahmad and Bouchachia, Hamid and Gegov, Alexander and Langensiepen, Caroline and McGinnity, Martin},
	year = {2019},
	keywords = {Classification algorithms, Heterogeneous datasets, Similarity measures, Two-dimensional similarity space},
	pages = {252--263},
	file = {Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\2B7ZHQHD\\Ali et al. - 2019 - Classification of Heterogeneous Data Based on Data.pdf:application/pdf},
}

@misc{noauthor_introduction_nodate,
	title = {An {Introduction} to {Statistical} {Learning} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/book/10.1007/978-1-4614-7138-7},
	urldate = {2022-10-21},
	file = {An Introduction to Statistical Learning | SpringerLink:C\:\\Users\\danie\\Zotero\\storage\\UJPQMADJ\\978-1-4614-7138-7.html:text/html},
}

@article{gareth_introduction_2013,
	title = {An introduction to statistical learning with applications in {R}},
	volume = {6},
	issn = {2475-4269, 2475-4277},
	shorttitle = {An introduction to statistical learning with applications in {R}},
	url = {https://www.tandfonline.com/doi/full/10.1080/24754269.2021.1980261},
	doi = {10.1080/24754269.2021.1980261},
	language = {en},
	number = {1},
	urldate = {2022-10-21},
	journal = {Springer Science and Business Media},
	author = {Gareth, James and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	pages = {612},
	file = {An Introduction to Statistical Learning with Applications in R.pdf:C\:\\Users\\danie\\Zotero\\storage\\8LDUAQ3P\\An Introduction to Statistical Learning with Applications in R.pdf:application/pdf;Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:C\:\\Users\\danie\\Zotero\\storage\\85G2D7B4\\Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:application/pdf},
}

@book{russell_artificial_2010,
	address = {Upper Saddle River},
	edition = {3rd ed},
	series = {Prentice {Hall} series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial intelligence},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
	year = {2010},
	keywords = {Artificial intelligence},
	file = {Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:C\:\\Users\\danie\\Zotero\\storage\\P3EJVCGP\\Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:application/pdf},
}

@article{martin-barragan_interpretable_2014,
	title = {Interpretable support vector machines for functional data},
	volume = {232},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221712006406},
	doi = {10.1016/j.ejor.2012.08.017},
	abstract = {Support Vector Machines (SVMs) is known to be a powerful nonparametric classification technique even for high-dimensional data. Although predictive ability is important, obtaining an easy-to-interpret classifier is also crucial in many applications. Linear SVM provides a classifier based on a linear score. In the case of functional data, the coefficient function that defines such linear score usually has many irregular oscillations, making it difficult to interpret. This paper presents a new method, called Interpretable Support Vector Machines for Functional Data, that provides an interpretable classifier with high predictive power. Interpretability might be understood in different ways. The proposed method is flexible enough to cope with different notions of interpretability chosen by the user, thus the obtained coefficient function can be sparse, linear-wise, smooth, etc. The usefulness of the proposed method is shown in real applications getting interpretable classifiers with comparable, sometimes better, predictive ability versus classical SVM.},
	language = {en},
	number = {1},
	urldate = {2022-11-05},
	journal = {European Journal of Operational Research},
	author = {Martin-Barragan, Belen and Lillo, Rosa and Romo, Juan},
	month = jan,
	year = {2014},
	keywords = {Classification, Interpretability, Data mining, Functional data analysis, Linear programming, Regularization methods},
	pages = {146--155},
	file = {Accepted Version:C\:\\Users\\danie\\Zotero\\storage\\E4SI9S5E\\Martin-Barragan et al. - 2014 - Interpretable support vector machines for function.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\danie\\Zotero\\storage\\IJTLJAU8\\S0377221712006406.html:text/html},
}

@inproceedings{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	urldate = {2022-11-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\9AV2W6I2\\Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf},
}

@article{landis_measurement_1977,
	title = {The {Measurement} of {Observer} {Agreement} for {Categorical} {Data}},
	volume = {33},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2529310},
	doi = {10.2307/2529310},
	abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
	number = {1},
	urldate = {2022-11-11},
	journal = {Biometrics},
	author = {Landis, J. Richard and Koch, Gary G.},
	year = {1977},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {159--174},
}

@article{landis_measurement_1977-1,
	title = {The {Measurement} of {Observer} {Agreement} for {Categorical} {Data}},
	volume = {33},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2529310},
	doi = {10.2307/2529310},
	abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
	number = {1},
	urldate = {2022-11-11},
	journal = {Biometrics},
	author = {Landis, J. Richard and Koch, Gary G.},
	year = {1977},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {159--174},
}

@article{sarker_deep_2021,
	title = {Deep {Learning}: {A} {Comprehensive} {Overview} on {Techniques}, {Taxonomy}, {Applications} and {Research} {Directions}},
	volume = {2},
	issn = {2661-8907},
	shorttitle = {Deep {Learning}},
	url = {https://doi.org/10.1007/s42979-021-00815-1},
	doi = {10.1007/s42979-021-00815-1},
	abstract = {Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of todayâ€™s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics,Â cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals.},
	language = {en},
	number = {6},
	urldate = {2022-11-12},
	journal = {SN Computer Science},
	author = {Sarker, Iqbal H.},
	month = aug,
	year = {2021},
	keywords = {Artificial intelligence, Artificial neural network, Deep learning, Discriminative learning, Generative learning, Hybrid learning, Intelligent systems},
	pages = {420},
	file = {Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\6E4W563S\\Sarker - 2021 - Deep Learning A Comprehensive Overview on Techniq.pdf:application/pdf},
}
