---
title: |
  \textbf{Exploratory Data Analysis on Housing Market in Italy} \vspace {1cm}
subtitle: |
  \Large Supervised Learning & Visualization \vspace {1cm}
  
  ![](img/italymap.png){width=2in}  
author: 
- Daniel Anadria
- Kyuri Park 
- Ernst-Paul Swens
- Emilia Löscher 
date: "October 3, 2022"
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    toc_depth: 1
    df_print: kable
    highlight: tango
  html_document:
    toc: true
    toc_float: true
    number_sections: true
geometry: "left = 2cm, right = 2cm, top = 2cm, bottom = 2cm"
linkcolor: NavyBlue
fontsize: 11pt
---
<style type="text/css">
@import url('https://fonts.googleapis.com/css2?family=Lato:wght@300;400&display=swap');

body{ /* Normal  */
  font-size: 13px;
  font-family: 'Lato', sans-serif;
  }
h1.title {
  font-size: 25px;
  color: DarkBlue;
  margin-bottom:5px;
}
.author{
  display: inline-block;
  padding: 5px;
}
h1 { /* Header 1 */
  font-size: 20px;
  font-weight: bold;
}
h2 { /* Header 2 */
  font-size: 15px;
  line-height: 1.6;
}
h3 { /* Header 3 */
  font-size: 14px;
  line-height: 1.6;
}
pre { /* Code block */
  font-size: 13px;
}
td {  /* Table  */
  font-size: 12px;
}
.subtitle p{
  font-size: 20px;
  font-weight: bold;
}
.author{
 font-size: 15px;
}
.date{
 font-size: 15px;
}
</style>
<hr>

```{r setup, include=FALSE}
options(warn = -1) # suppress ggplot warnings
knitr::opts_chunk$set(message = FALSE,
   warning = FALSE,
   comment = NA)
```

# Introduction
\vspace{-0.5cm}
This is an exploratory data analysis of the Italian housing market in 2022. 
For context, Italy contains a total of 20 regions (*regioni*), 107 provinces (*province*) and 7,904 municipalities (*comuni*). In the present work, we pose several interesting research questions which can be answered by means of data visualization and summary statistics.

## The Dataset

Our dataset originates from [Kaggle](https://www.kaggle.com/datasets/tangelus/housing-data-in-italy-august-2022?resource=download). 
It contains information about the housing market in Italy in 2022.
The data were scraped from one of the most prominent housing sales websites in Italy during the month of *August 2022*. The data consist of more than 223,000 sales posts spread over 7,023 (89% coverage) Italian municipalities.
We do not have any information on the representativeness of our dataset. Hence, we advise caution when drawing inferences from our findings.

In order to plot the statistics of interest to maps of Italy, we use the regional and provincial shape files, which are obtained from the *Italian National Institute of Statistics* [(ISTAT)](https://www.istat.it/it/archivio/222527). 
These files contain the regional and provincial coding and geographical shape information, which can be used to cluster the [municipalities](https://en.wikipedia.org/wiki/Comune) in our `location` variable into their respective provinces and regions. 

For each housing sale post, the dataset contains the following variables:

| **Variable**          | **Description**                              |
| :-------------------- | :------------------------------------------- |
|`id`                   | ID of the sale                               |
|`timestamp`            | Timestamp consisting of 10 digits            |
|`location`             | Location on municipality level               |
|`title`                |  Short description of property               |
|`price`                |  Price in Euros                              |
|`n_rooms`              | Number of rooms                              |
|`floor`                | Floor                                        |
|`mq`                   |       Size in square meters                  |
|`n_bathrooms`          |   Number of bathrooms                        |
|`year_of_construction` | Year of construction                         |
|`availability`         | Availability of property                     |
|`energy_class`         | Energy class ranging from a+ to g            |
|`status`               |   Status of the property                     |
|`heating`              |    Type of heating                           |
|`has_garage`           | Garage present: yes (1), no (0)              |
|`has_terrace`          |   Terrace present: yes (1), no (0)           |
|`has_garden`           | Garden present: yes (1), no (0)              |
|`has_balcony`          | Balcony present: yes (1), no (0)             |
|`has_fireplace`        |  Fireplace present: yes (1), no (0)          |
|`has_alarm`            |  Alarm present: yes (1), no (0)              |
|`has_air_conditioning` | Air Conditioning present: yes (1), no (0)    |
|`has_pool`             | Pool present: yes (1), no (0)                |
|`has_parking`          | Parking present: yes (1), no (0)             |
|`has_elevator`         | Elevator present: yes (1), no (0)            |
|`is_furnished`         | Furniture present: yes (1), no (0)           |
Table: Description of Variables in the Italy Housing Dataset


# Preparation

In order to start our exploratory analysis, we first load relevant packages and import the dataset as well as the ISTAT shape files. 

## Load Packages & Import Data

```{r libraries+datasets, results='hide'}
## load packages
library(tidyverse)   # for wrangling data
library(magrittr)    # for using pipes
library(skimr)       # for skimming data 
library(sf)          # for spatial analysis
library(sp)          # for spatial analysis
library(ggplot2)     # for plotting
library(fuzzyjoin)   # for joining on not-exact matches
library(ggpubr)      # for arranging ggplots
library(mice)        # for imputation procedure

## import italy housing data
houses <- read.csv("data/housing_data_italy_august2022.csv", 
                    na.strings=c("","NA"), header = TRUE)

## import istat shape files
# municipality
municipalities <- st_read("data/italy_shape_2022_files/Com01012022_g")
municipalities <- municipalities[c("COD_REG", "COD_PROV", "COMUNE")]  
# province
provinces <- st_read("data/italy_shape_2022_files/ProvCM01012022_g") 
# region
regions <- st_read("data/italy_shape_2022_files/Reg01012022_g")
```

# Exploratory Research Analyses

We focus on following the exploratory analyses:    

1. Exploring the missingness in the dataset.    

2. Investigating whether there are any geographical trends in the median housing prices and their absolute deviations on regional and/or provincial level?   

# Data Cleaning
\vspace {-0.3cm}
***Note***: We base the following data cleaning on the summary of the raw dataset, which can be found in the *Appendix*.  

The original data consist of 223,409 rows (*sales*) and 25 columns (*variables*).  
Given our research questions, we exclude `id` (*ID of the sale*), `timestamp` (*timestamp of the sale*), and `title` (*description of the property*) as they are deemed irrelevant.
In addition, we exclude two columns that have only one unique value (`status` and `availibility`), as these are not variables but constants.

We observe that the types of some variables are wrongly specified. We convert them to a correct type (e.g., `heating`: character$\rightarrow$factor, `has_xxx`: numeric$\rightarrow$factor, `is_furnished`: numeric$\rightarrow$factor).

Next, we create a new variable `property_age` by subtracting the `year_of_construction` from 2022. In the original dataset, there are some unreasonable years of construction (e.g., 2209). While some properties may be sold before their construction is completed, we deem it unlikely for properties whose `year_of_construction` is more than 4 years later as of now. Thus, we filter out those with `year_of_construction` > 2026. 

For the second exploratory research question, the variable of our main interest is `price`. When taking a closer look at this variable, we see that it is highly skewed to the right given that the mean (239,939) is far off to the right of the median (135,000). We take a closer look at the distribution of the `price` with the help of a boxplot to examine the outliers (see *Figure 1*). 

```{r figure1, out.width="70%", fig.align='center', fig.show='hold',fig.cap="Boxplot of Housing Prices in Italy"}
## create our own theme that can be used throughout
custom.theme = theme(
  axis.title.x = element_text(size = 14),
  axis.text.x = element_text(size = 13),
  axis.title.y = element_text(size = 14),
  axis.text.y = element_text(size = 13))

## boxplot of price
houses %>% 
   ggplot(aes(x=price)) +
   geom_boxplot() + 
   # add comma on the x-axis labels
   scale_x_continuous(labels=scales::label_comma(), 
   # rotate the x-axis labels
   guide = guide_axis(angle = 25)) +
   # apply minimal theme plus our own theme
   theme_minimal() + custom.theme
```
From *Figure 1*, we observe that there are extreme outliers in `price`. Some housing prices in the dataset are exorbitant (e.g., over €2B). We decide to focus the scope of our analysis on the houses whose price is less than or equal to €1M. The distribution of housing prices after filtering can be seen in *Figure 2*.

```{r figure2, out.width="70%", fig.align='center',fig.show='hold', fig.cap="Histogram and Density Plot of Housing Price After Filtering"}
## density plot of price (cleaned dataset)
houses %>% 
  # filter the price over a million
  filter(price <= 1e6 | is.na(price)) %>% 
  # create a ggplot
  ggplot(aes(price)) + 
  # add histogram 
  geom_histogram(aes(y=..density..), bins = 30, color = 1, fill="white") + 
  # add density line
  geom_density(lwd=0.5, color = "#165e70", fill = "#165e70", alpha = 0.2) + 
  # apply our theme
  theme_minimal() + custom.theme
```
From *Figure 2*, we take that the distribution of housing prices after filtering shows that there is still a long right tail, but that is to be expected with housing prices in any country. The extreme outliers have been eliminated. From this plot, we also conclude that when working with housing price data, it is advisable to use centrality and spread measures that are robust to skewed data. For this reason, we will use the *median* and *median absolute deviation (MAD)* instead of the mean and variance in our exploration of the present dataset. 

```{r data_cleaning}
## cleaning up the housing data
houses.cleaned <- houses %>% 
  # only select variables that have more than one unique value
  select(where(~n_distinct(.) > 1)) %>% 
  # fix the data type (convert them to factor)
  mutate(across(c(starts_with("has"), is_furnished, heating, energy_class, n_rooms, 
                  n_bathrooms, location), factor)) %>%
  # filter out houses whose price is over a million (while keeping NAs)
  filter(price <= 1e6 | is.na(price), 
  # filter out houses with a built year over 2026 (while keeping NAs)
         year_of_construction < 2026 | is.na(year_of_construction)) %>% 
  # create property age variable
  mutate(property_age = 2022 - as.numeric(year_of_construction)) %>% 
  # remove id, timestamp, title and year_of_construction
  select(-c(id, timestamp, title, year_of_construction)) 
```

## Data Summary

After data cleaning, we take a look at the summary statistics to get a better overview of our data.
We skim through our cleaned dataset using the `skimr` package.

```{r data_summary}
# settings: round up by 2 decimal places & disable scientific notation
options(digits = 3, scipen = 999) 
# specify skimming function
custom.skim <- skim_with(character = sfl(whitespace=NULL, min = NULL, max = NULL),
   factor = sfl(ordered = NULL),
   numeric = sfl(p0 = NULL, p25=NULL, p50=NULL, p75=NULL, p100=NULL, hist=NULL, 
                 median = ~median(., na.rm=T), 
                 min = ~min(., na.rm=T), max = ~max(., na.rm=T), n_unique=n_unique))
# summary table
custom.skim(houses.cleaned) 
```

From the output, we see that our cleaned dataset has 220,607 rows and 20 columns, 16 of which are factors, and 4 of which are numeric types. The output is presented in two tables for factor and numeric variables, separately. 

From the table of factor variables, we again see that `location` has 7023 unique values (i.e., municipalities).  Also, there are some missing values for `energy_class` and a lot of missing values for `n_rooms` and `n_bathrooms`. The ratio of properties having an alarm is highest (99.10\%) and lowest for having air conditioning (70.24\%). Three rooms, one bathroom, automonous heating and energy class g were the most frequent levels of the respective factors. 

From the table of numeric variables, we see that all numeric variables have some missing values. For about 18% of `price`, the variable of our main interest, is missing and we look into this more in detail when we address the 2nd question regarding the missingness in `price`. Furthermore, we see that the median number of floor is 2 and the maximum is 52. The average number of square meters for this data set from Italy is 156.1 $m^2$ and while the oldest building according to the giving data is 1022 years old, the average age of the buildings is 56.1 years. 
***@ALL: Any other statistics interesting? mean, sd?.. something? Already added something. Min for square meter is 1?! (Emilia)***

# Exploratory Data Analysis
In the following we are performing the exploratory data analyses. First, we explore the missingness in the dataset. Afterwards, we explore trends in *house price* on the regional and provincial level. 

## Question 1: Exploring missingness in the dataset.
As we later want to analyze the data on the regional and provincial level, we also want to explore the missingness on these levels. Therefore, we aggregate the data from a municipality level to the regional and provincial level. This process is described in the following section. 

## Geographical Data Preparation 
At the beginning of the assignment, we loaded the *ISTAT* shape files. These files are useful for two reasons.
First, they contain the list of all Italian municipalities, their respective provinces and regions.
Therefore, we can use this data to append our original dataset with additional location indicators.
Second, they contain the shapes of Italy divided into provinces and regions. 
This is particularly useful for creating map plots using `ggplot2`.

Each sale in our dataset is assigned to one of 7023 municipalities. In order to create plots which visualize the differences in average housing prices across Italy, we assign each municipality to its corresponding province and region. We use the data from *ISTAT* to append the province and region information to every observed municipality in our dataset. 
We use fuzzy matching for inexact matches as we found that there were some minor inconsistencies in how the municipalities were named in our dataset as opposed to their names in the ISTAT shape files. The result of the following chunk of code is that all the municipalities are assigned their regions and provinces.

```{r eval=FALSE, include=FALSE}
# create predictor matrix
predictors <- houses.cleaned %>% ungroup() %>% quickpred()

# multiple imputation procedure (m = 5)
imputations <- mice(houses.cleaned, m = 5, seed = 1, predictorMatrix = predictors)
```

```{r}
## load imputation results
imputations <- readRDS("data/imputation.rds")
```

```{r prepgeo, eval=FALSE, cache=TRUE, include=FALSE}
## function to join geospatial data 
join.geo <- function(data) {
   data.geo <- stringdist_left_join(data, municipalities, 
         by = c("location" = "COMUNE"), distance_col = "distance", 
         ignore_case = TRUE) %>% 
      group_by(location) %>% 
      slice_min(distance) %>%
      select(-geometry,-distance) %>% 
      left_join(., as.data.frame(regions[,c("COD_REG","DEN_REG")])) %>% 
      select(-geometry, -COMUNE) %>% 
      left_join(., as.data.frame(provinces[,c("DEN_UTS", "COD_PROV")], 
         by = "COD_PROV")) %>%
      rename(region = DEN_REG, province = DEN_UTS) %>%
      select(-geometry, -COD_REG, -COD_PROV) %>%
      relocate(c(region, province), .after = location) 
}

# join geospatial data to the imputed data
imputed <- lapply(complete(imputations, "all"), join.geo)

# join geospatial data to the cleaned house data
houses.cleaned <- join.geo(houses.cleaned)
```

```{r}
# load the imputed data including the geospatial data
imputed <- readRDS("data/imputed.rds")

# load the cleaned house data including the geospatial data
houses.cleaned <- readRDS("data/housescleaned.rds")
```

To answer our first research question, we aggregate our data on two levels: 1) regional and 2) provincial level by computing two aggregated statistics: 1) the median housing price and 2) the median absolute deviation (MAD) in housing price on the two respective levels. This yields two sub-datasets, one per each level. To each, we attach geometric information needed for geographic plotting and convert it to an `sf` object which is a requirement for plotting maps.

Having done this, we are ready to explore the missingness in the dataset.

First, we do so by calculating and plotting the proportion of missing values for all the variables in *Figure 3 A*.

```{r missingness, fig.cap = "Proportion of Missing Values", fig.width=9, fig.height=5}
# barplot to show the missingness per variable
houses.cleaned %>%
   # get the average missing proportion
   is.na() %>% colMeans() %>% stack() %>% 
   # create ggplot for the missing proportion
   ggplot(aes(x = reorder(ind, values), y=values)) +
   # specify the bar plot
   geom_bar(stat="identity", width = .2, fill = "black", 
            position = position_dodge2(padding = 0.8)) + 
   # flip the bar plot and add the points
   geom_point() + coord_flip() + 
   # apply our custom theme
   theme_minimal() + custom.theme +
   # specify axis labels
   labs(x = "", y = "Missingness (%)") 
```

The plot shows that the percentage of missing values lies above 30\% for the variable *floor* and above 25\% for the *number of rooms*. Furthermore, about 18\% of the *housing prices* are missing. Except for the *number of bathrooms* which has about 6\% values missing, for the remaining variables less than 3\% are missing, respectively. 

In the following, we explore the correlation of *price* and the other variables and summarize the findings in *Table 5*.
```{r}
houses.cleaned %>%
  # create missingness indicator of price
  mutate(na_ind = ifelse(is.na(price), 1, 0)) %>% 
  ungroup() %>% 
  # compute correlation
  summarize(across(n_rooms:property_age, ~cor(as.numeric(.x), na_ind, 
                                              use = "pairwise.complete.obs"))) %>% 
  # sort them in descending order based on their absolute values
  t(.) %>% .[order(abs(.), decreasing = TRUE),] %>% 
  # create a neat table
  knitr::kable(col.names = "correlation", caption = "Correlation between missingness 
               of price and other variables", align="c")
```

The missingness of `price` appears to be moderately correlated with the `energy_class` (*cor = -0.271*). Hence, we further check what the pattern of missingness in price across different energy classes looks like.

```{r corrplots, fig.cap = "Missing Values in Price across Different Energy Classes", out.width="80%", fig.align='center'}
## create plots for missingness in price vs energy class
houses.cleaned %>%
  # add price missingness indicator
  mutate(na_ind = ifelse(is.na(price), 1, 0)) %>% 
  # group by energy class
  group_by(energy_class) %>% 
  # sum up all the missingness in price per energy class
  summarize(n = sum(na_ind)) %>% 
  # create a ggplot for the sum of missingness
  ggplot(aes(x = energy_class, y = n, fill = energy_class)) +
  # turn off legend
  geom_col(show.legend=FALSE) + 
  # customize the color
  scale_fill_manual(values = c("#F8766D", "#999999","#F8766D", 
                                     rep("#999999", 8),"#F8766D")) +
  # apply the themes to the bar plot
  theme_minimal() + custom.theme +
  # change the labels
  labs(x = "Energy Class", y = "Missingness in price")
```
*Figure 4* shows that there is higher missingness in price for houses that either have a good energy class of *a* or *a1*, or fall into the very inefficient energy class *g*. There is low missingness in *price* for the other energy classes and for houses for which *price* is missing. 

We also check the missingness in price across different regions to see if there are any patterns.

```{r, fig.cap = "Missingness of Price per Region", out.width="80%", fig.align='center'}
## check missingness in price w.r.t regions
houses.cleaned %>% 
   # add price missingness indicator
   mutate(na_ind = ifelse(is.na(price), 1, 0)) %>%
   group_by(region) %>%
   # get the total missingness proportion per region
   summarize(`Average missing proportion (%)` = sum(na_ind) / n()) %>%
   # add the spatial data
   left_join(., regions, by = c("region" = "DEN_REG")) %>% 
   st_as_sf() %>%
   ggplot() +
   # plot the italy map
   geom_sf(fill=NA) +
  # add scatter plots of missingness proportion per region
   geom_point(color = alpha("red", 0.4),
   aes(size = `Average missing proportion (%)`, geometry = geometry),
   stat = "sf_coordinates") +
  scale_size(range = c(1, 5)) +
  # remove unnecessary coordinates
   theme_void() + 
  
   theme(legend.position = "bottom")
  
```

*Figure 5* shows that the proportion of missing data in `price` is not equal across different regions. 

<!-- Therefore, we explored if the missingness of the predictors and the outcome variable *house prices* are related. First, we investigated the correlation between the missingness indicator for *price* and the predictors. Second, we visually examined the relationship between the predictors' missingness indicators and the *price* densities. Lastly, we visually inspected the percentage of missingness per region.   -->

Next, we examine the relationship between the predictors' missingness indicators and the *price* densities by plotting the density of price (on a log10-scale) split by whether or not the respective value for a given variable is missing or not. These results provide us with some indication of the missing data mechanism. Specifically, if missing completely at random (MCAR) is plausible to assume or not.

```{r missingness_density, fig.cap = "Density Plots for Price based on the Missing Indicators"}
## function to create a density plot of price with missing indicator
missing.plots <- function(x) {
   plot <- houses.cleaned %>% ungroup() %>%
      mutate(missing = is.na(.[,x])) %>%
      ggplot(aes(x = log10(price), fill = missing)) + 
      geom_density(alpha = 0.5, color = NA) + 
      theme_classic() + 
      labs(x = expression(paste(Log["10"],"(Price)"), y = "Density")) + 
      scale_x_continuous(limits = c(2, 7)) + ylim(0, 1.5)
   return(plot)
}

# multiple plots for floor, no. of rooms, no. of bathrooms, and meters squared
ggarrange(missing.plots("floor"), 
          missing.plots("n_rooms"),
          missing.plots("n_bathrooms"),
          missing.plots("mq"),
          labels = c("         A. Floor", "B. Number of rooms", "C. Number of bathrooms", "D. Squared meter(m2)"),
                     font.label=list(color="black",size = 10),
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "bottom")
```

The missingness of number of floors (*Figure 6 A*) and number of rooms (*Figure 6 B*) does not seem to be dependent on the observed price information. Whereas for the number of bathrooms (*Figure 6 C*) and the meters squared (*Figure 6 D*) missingness shows a different result, namely, missingness tends to occur at higher house prices.

### Conclusion
For the first question, we explored missingness in the dataset. We saw that there are quite a lot of missing values for the *floor*, the *number of rooms*, the *number of bathrooms*, and *house price*. As *house price* is of interest for the second question, we took a closer look and realized that missingness on *price* is correlated, e.g., with *energy class* and that the amount of missingness varies across regions. 

We also examined if the missingness of the variable *house price* and the other variables are related. From our results it appears that they are. Hence, it is unlikely that the missingness mechanism is MCAR. Therefore, we include a multiple imputation procedure before investigating geographical trends in the median and the MAD.

### Imputation
We limited the diagnostics for the imputation procedure to the convergence of the algorithm and plausibility of the imputed data. There appeared to be no convergence issues and the imputed data appeared to be plausible with respect to the observed data (see Appendix).

## Question 2: Regional and Provincial Trends in the Median Housing Price and the Median Absolute Deviations in Italy
We use the imputed dataset to explore whether there is a geographical trend in the median and the median absolute deviation (MAD) *housing price* on a regional or provincial level. In order to do so, we plot the median and the MAD on the regional and the provincial level:

```{r}
## function to get aggregated region price information 
group.region <- function(data, estimate) {
   data %>% 
      group_by(region) %>%
      summarize(estimate = ifelse(estimate, median(price), mad(price))) %>%
      select(-region)
}

region.median <- lapply(imputed, group.region, estimate = T) %>% 
   do.call(cbind, .) %>% rowMeans() 
region.mad <- lapply(imputed, group.region, estimate = F) %>% 
   do.call(cbind, .) %>% rowMeans() 

labels <- c("Trentino-Alto Adige", "Molise", "Piemonte", "Bolzano", "Calabria")

price.by.region <- data.frame(region = sort(regions$DEN_REG), 
   median = region.median, mad = region.mad) %>% 
   left_join(.,regions, by = c("region" = "DEN_REG")) %>% st_as_sf() %>%
   mutate(label = ifelse(region %in% labels, region, NA))
```

```{r}
## function to get aggregated province price information
group.province <- function(data, estimate) {
   data %>% 
      group_by(province) %>%
      summarize(estimate = ifelse(estimate, median(price), mad(price))) %>%
      select(-province)
}

province.median <- lapply(imputed, group.province, estimate = T) %>% 
   do.call(cbind, .) %>% rowMeans() 
province.mad <- lapply(imputed, group.province, estimate = F) %>% 
   do.call(cbind, .) %>% rowMeans() 

price.by.province <- data.frame(province = sort(provinces$DEN_UTS), 
   median = province.median, mad = province.mad) %>% 
   left_join(., provinces, by = c("province" = "DEN_PROV")) %>% st_as_sf()
```

```{r median_mad_region}
plot.list.1 <- list()

## median & mad of price per region 
plot.list.1 <- map(
  c("median", "mad"),
  function(var) {
    ggplot(price.by.region) +       
      # map each statistic
      geom_sf(aes(fill = .data[[var]])) +
      # void theme: remove all unncessary coordinates
      theme_void() +
      # add labels to specific regions
      geom_sf_label(aes(label = label)) + 
      # color-scheme (color-blind friendly???)
      scale_fill_viridis_c(option = "E", direction = -1) +
      # lengthen the legend
      theme(legend.key.width= unit(2, 'cm'))
     }
  )
plot.list.2 <- list()

## median & mad of price per province 
plot.list.2 <- map(
  c("median", "mad"),
  function(var) {
    ggplot(price.by.province) +
      # map each statistic
      geom_sf(aes(fill = .data[[var]])) +
      # void theme: remove all unncessary coordinates
      theme_void() +
      # color-scheme (color-blind friendly???)
      scale_fill_viridis_c(option = "E", direction = -1) +
      # lengthen the legend
      theme(legend.key.width= unit(2, 'cm'))
     }
  )

# combine the plot lists
plot.list <- c(plot.list.1, plot.list.2)
```

```{r fig.cap="Median of Price per Region (left) and Province (right)", out.width="80%", fig.align='center'}
## plot the median of price
ggarrange(plotlist = plot.list[c(1,3)], nrow = 1, ncol = 2, common.legend = TRUE, 
          legend = "bottom")
```

```{r fig.cap="MAD of Price per Region (left) and Province (right)", out.width="80%", fig.align='center'}
## plot the mad of price
ggarrange(plotlist = plot.list[c(2,4)], nrow = 1, ncol = 2, common.legend = TRUE, 
          legend = "bottom")
```

On the regional level, we see that the median for the region *Trentino-Alto Adige* (200 000€) are the highest, and the lowest for *Molise* (79 000€). We recognize a trend that the median price is lower for more Southern regions in Italy. The only exception from this is the region of *Piemonte* (99 000€) which has a lower median price than the surrounding regions in the North. Regarding the MAD, a measure of variability within a region, we see that it is highest for the regions with higher median prices. This is recognizable as the color patterns in the median plot and the MAD plot are very similar. 

On the provincial level, it can be seen that the high median of the *Trentino-Alto Adige* region is mainly due to the high median of 400 000€ in the province of *Bolzano*. As the other provinces in that region have lower median prices, the MAD in that region is comparably high. 
The opposite is the case within the Southern regions, here, the provinces that make up the region of *Calabria* for example, all have a low median price. Hence, the MAD for that region is low. 

Given that the overall geographical pattern for median and MAD of `price` correspond to each other, it is interesting to investigate further the possible differences in the distribution of `price` between high- and low-median regions.
```{r groupdiff, fig.cap="group differences in price distribution"}
# top 2 high median regions
top.2.median <- price.by.region %>% slice_max(median, n = 2) %>% pull(region)

# lowest 2 low median regions
lowest.2.median <- price.by.region %>% slice_min(median, n = 2) %>% pull(region)

# plot the histograms for each region in the high and low median groups
imputed[[1]] %>% 
  # subset top two and bottom two countries
  filter(region %in% c(top.2.median, lowest.2.median)) %>%
  # group by the regions
  group_by(region) %>%  
  # create the grouping variable for coloring 
  mutate(grouping = ifelse(region %in% top.2.median, "high median", "low median"),
         # get the median price for each region
         med_price = median(price, na.rm=T)) %>% 
  # create ggplot for price (coloring by groups)
  ggplot(aes(x = price, fill = grouping)) +
  geom_histogram(bins = 30) +
  # create a panel of plots per region
  theme_bw() + facet_wrap(~region) +
  # indicate the median price by a vertical line
  geom_vline(aes(xintercept = med_price, group=region), linetype="dashed") +
  # change legend title
  labs(fill = "high/low regions")  
```

An interesting take-away from *Figure 9* is that all the densities for the *house price* are right skewed. This is reasonable for house prices as one would expect that there are more cheap and moderately priced houses and only few very expensive houses. Furthermore, it is apparent that there are most sells in the dataset from the *Toscana* region and there are only very few very expensive houses in the regions of *Calabria* and *Molise* as one would expect with those regions having a lower median.

### Conclusion
All things considered, we found a general decrease in the median price when moving from Northern to Southern Italy. We also showed that higher medians on a regional level are due to a higher median on the province level with one region having a particular high median. Consequently, such regions where there is one province with a higher median of *house price*, the MAD is higher too if the other provinces in that region do not have a high median.
Furthermore, by including the plots on the province level, it was recognizable that there were no sales in some provinces. ***How many provinces did not have data?*** 

# Overall Conclusion
All things considered, we identified that there is quite some missingness present - especially for *house price* for which about 18\% of values were missing. The absolute correlation of missingness in *house price* was highest with *energy class* (-0.27). As we were not able to conclude from our analysis that the missingness mechanism is MCAR, we decided to impute the missing values.

Using the imputed dataset, we explored the median and the mediane absolute deviation on the regional and provicial level in Italy. We found a trend in the median price from more expensive to cheaper when going from North to South in Italy. We also have shown that these higher medians on a regional level are due to a higher median on the provincial level. In most cases, the MAD for such regions was high, too, as there frequently is one province with a higher median of *house price* and the MAD is consequently higher if the other provinces in that region do not have a high median, too. 

# Appendix \label{ref:appendix}

## Summary of the raw data using the my_skim function.

```{r}
custom.skim(houses)
```

## Convergence of the algorithm and plausability of the imputed dataset
```{r}
# convergence of the algorithm
plot(imputations)

# plausibility of the imputed data
densityplot(imputations, ~n_rooms + mq + floor + n_bathrooms + price, lwd = 2)
```
