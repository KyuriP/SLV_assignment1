---
title: "SLV Assignment1"
author: 
- Daniel Anadria
- Kyuri Park 
- Ernst-Paul Swens
- Emilia Loescher
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
  html_document:
    toc: true
    toc_float: true
geometry: "left = 2cm, right = 2cm, top = 2cm, bottom = 2cm"
# mainfont: Georgia
# sansfont: Georgia
linkcolor: NavyBlue
---
<style type="text/css">
@import url('https://fonts.googleapis.com/css2?family=Lato:wght@300;400&display=swap');

body{ /* Normal  */
  font-size: 13px;
  font-family: 'Lato', sans-serif;
  }
h1.title {
  font-size: 25px;
  color: DarkBlue;
  margin-bottom:5px;
}
.author{
  display: inline-block;
  padding: 5px;
}
h1 { /* Header 1 */
  font-size: 20px;
  font-weight: bold;
}
h2 { /* Header 2 */
  font-size: 15px;
  line-height: 1.6;
}
h3 { /* Header 3 */
  font-size: 14px;
  line-height: 1.6;
}
pre { /* Code block - determines code spacing between lines */
  font-size: 13px;
}
td {  /* Table  */
  font-size: 12px;
}
</style>
<hr>

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               comment = NA)
```

***Frontpage with toc***

\newpage
# Introduction

## The Dataset

We explore a dataset from [kaggle](https://www.kaggle.com/datasets/tangelus/housing-data-in-italy-august-2022?resource=download), which contains information about the housing market in Italy.
The data were scraped from one of the most relevant housing sales websites in Italy during the month of *August 2022*. The data consist of more than 223,000 sales posts spread over 7,023 (89% of the total 7,904) Italian municipalities (*comuni*).
Some of the entries were removed in dataset construction due to translation limitations (e.g., extended text-based description, specific url of the post). 

In order to plot the statistics of interest to maps of Italy, we use the regional and provincial shape files which we obtained from the [Italian National Institute of Statistics](https://www.istat.it/it/archivio/222527). 
These files contain the regional and provincial coding and geographical shape information which can be used cluster the [comuni](https://en.wikipedia.org/wiki/Comune) in our data (`location`) into (107) provinces and (20) regions. 

For each sale, the dataset contains the following variables:

| **Variable**        | **Description**                    |
| :------------------ | :------------------------------|
|id                   | ID of the sale                               |
|timestamp            | Timestamp consisting of 10 digits            |
|location             | Location on municipality level               |
|title                |  Short description of property                              |
|price                |  Price in Euros                              |
|n_rooms              | Number of rooms                               |
|floor                | Floor                              |
|mq                   |       Size in square meters                 |
|n_bathrooms          |   Number of bathrooms                     |
|year_of_construction | Year of construction                       |
|availability         | Availability of property                     |
|energy_class         | Energy class ranging from a+ to g                       |
|status               |   Status of the property                             |
|heating              |    Type of heating                             |
|has_garage           | Garage present: yes (1), no (0)             |
|has_terrace          |   Terrace present: yes (1), no (0)            |
|has_garden           | Garden present: yes (1), no (0)              |
|has_balcony          | Balcony present: yes (1), no (0)              |
|has_fireplace        |  Fireplace present: yes (1), no (0)              |
|has_alarm            |  Alarm present: yes (1), no (0)       |
|has_air_conditioning | Air Conditioning present: yes (1), no (0)   |
|has_pool             | Pool present: yes (1), no (0)            |
|has_parking          | Parking present: yes (1), no (0)            |
|has_elevator         | Elevator present: yes (1), no (0)            |
|is_furnished         | Furniture present: yes (1), no (0)            |
Table: Description of



## Exploratory Questions (***EDIT LATER***)

We focus on four exploratory questions concerning housing data set in Italy.\

\textbf{Firstly}, we explore if there are any geographical trends in the mean and median housing prices in Italy. (E.g., Is housing more/less expensive in Northern Italy compared to Southern Italy?) \

\textbf{Secondly}, we examine if there are differences in mean regional variances of housing prices between the different provinces and regions. 

\textbf{Thirdly}, we explore if there is a correlation between the missingness of housing price and other variables. \

\textbf{Fourthly}, we identify the most important predictors of housing prices in Italy. \


# Preparation

In order to start our exploratory analysis, we first load relevant packages and import the full data set. 

## Load Packages & Import Data

```{r, results='hide'}
## load packages
library(tidyverse) # for wrangling data
library(magrittr) # for using pipes
library(skimr) # for skimming data 
library(sf) # for spatial analysis
library(sp) # for spatial analysis
library(ggplot2) # for plotting
library(fuzzyjoin) # for joining on not-exact matches
library(ggpubr) # for arranging ggplots


## import Italy housing data
housing <- read.csv("data/housing_data_italy_august2022.csv", na.strings=c("","NA"), header = TRUE)

## import Italy shape data
# municipality level
munic_2022 <- st_read("data/italy_shape_2022_files/Com01012022_g")[c("COD_REG","COD_PROV", "COMUNE")]  
# province level
prov_2022 <- st_read("data/italy_shape_2022_files/ProvCM01012022_g") 
# region level
reg_2022 <- st_read("data/italy_shape_2022_files/Reg01012022_g")
```

# Preliminary analysis

We skim through our data using the `skimr` package. This summary of the raw data set can be found in the section \ref{ref:appendix} Appendix.
The original data consist of 223,409 rows (sales) and 25 columns (variables).
Given our questions, we conclude that `id` (ID of the sale), `timestamp` (timestamp of the sale), and `title` (description of the property) are irrelevant and, hence, we exclude them from the dataset for further analysis.
In addition, we remove two columns that have only one unique value (`status`: "other" and `availibility`: "not free/other"), as these variables do not provide information specific to certain sales.

Furthermore, we observe that types of some variables are wrongly specified. We convert them to a correct type (e.g., `heating`: character --> factor, `has_xxx`: numeric --> factor, `is_furnished`: numeric --> factor).

We create a new variable `age` which contains the age of the property as of 2022 by subtracting the `year_of_construction` from 2022. In the original dataset, there are some unreasonable years of construction (e.g., 2209). Some properties may be sold before construction is completed, but we deem it unlikely for properties whose `year_of_construction` is more than 4 years later from now. Thus, we exclude the `age` of property lower than $-4$ (i.e., exclude `year_of_construction` > 2026).

The variable of our main interest `price` has some missing values, and we see that it is highly skewed to the right given that mean is far off to the right of the median (see section \ref{ref:appendix} Appendix). We look into the distribution of the `price` further in detail. As shown in Figure 1, there are extreme outliers in `price` that seem unrealistic (e.g., over 2 billion). We decide to filter out the houses whose price is over a million ***to prevent severe bias in our subsequent analyses ... KP: NOT SURE IF THIS IS CORRECT TO SAY*** (see Figure 2 for the distribution of the price for the filtered houses).
```{r datacleanup}
## cleaning up the housing data
cleaned_housing <- housing %>% 
  # select variables that have more than one unique value
  select(where(~n_distinct(.) > 1)) %>% 
  # fix the data type
  mutate(across(c(starts_with("has"), is_furnished, heating, energy_class, n_rooms, n_bathrooms, location), factor)) %>%
  # filter out houses whose price is over a million (while keeping NAs)
  filter(price < 1e6 | is.na(price), 
  # filter out houses whose construction year is more than 4 years later as of today 
         year_of_construction < 2026 |is.na(year_of_construction)) %>% 
  # create property age variable
  mutate(property_age = 2022 - as.numeric(year_of_construction)) %>% 
             # remove id, timestamp, title and year_of_construction
  select(-c(id, timestamp, title, year_of_construction)) 
```


```{r boxplot, out.width="70%", fig.align='center', fig.cap="Distribution of housing price"}
## boxplot of price
housing %>% 
ggplot(aes(x=price)) +
  geom_boxplot() + theme_minimal()
```

```{r pricedensity, out.width="70%", fig.align='center', fig.cap="Histogram of housing price (under a million)"}
## density plot of price (under million)
housing %>% 
  # filter out houses whose price is over a million
  filter(price < 1e6) %>% 
  ggplot(aes(price)) + 
  geom_histogram(aes(y=..density..), color=1, fill="white") + 
  geom_density(lwd=0.5, color = 4, fill=4, alpha=0.2) + theme_minimal()
```

## Data summary
After the cleaning up the data, we take a look at the summary statistics for the data set to get a better overview of our data. 

```{r}
# round up by 2 decimal places + disable scientific notation
options(digits = 2, scipen = 999) 
# specify skimming function
my_skim <- skim_with(character = sfl(whitespace=NULL, min = NULL, max = NULL),
                     factor = sfl(ordered = NULL),
                     numeric = sfl(p0 = NULL, p25=NULL, p50=NULL, p75=NULL,
                                   p100=NULL, hist=NULL, median = ~median(., na.rm=T), 
                                   min = ~min(., na.rm=T), max = ~max(., na.rm=T), n_unique=n_unique))
# summary table
my_skim(cleaned_housing) 
```

***DECRIBE THE SUMMARY TABLE as per changes***

From the tables, we can see that there are 12 different energy classes and 7023 different locations. When taking a closer look at the `location` variable, one can see that they are given on a municipality level.

For the numeric variables, we observe that several have lots of missing values (e.g., `price`, `n_rooms`, `floor`, `mq`, `n_bathrooms`). We will discuss how we want to deal with this in section \ref{ref:missingness}. 




# Main (exploratory) Analysis

## Question 1: Geographical Differences in the Mean and Median Housing Price

Each sale in our dataset is assigned to one of 7023 municipalities. 
In order to create plots which visualize the differences in average housing prices across Italy, we assign each municipality (*comune*) to its corresponding province (*provincia*) and region (*regione*). We use the data from the *Italian National Institute of Statistics* (*ISTAT*) to append the province and region information to every observed municipality in our dataset. 

### Preparation

At the beginning of the assignment, we loaded the *ISTAT* shape files. These files are useful for two reasons.
First, they contain the list of all Italian municipalities, their respective provinces and regions.
Therefore, we can use this data to append our original dataset with additional location indicators.
Second, they contain the shapes of Italy divided into provinces and regions. 
This is particularly useful for creating map plots using `ggplot2`.

For completeness of our dataset, we append the province and region information.
We use fuzzy matching for inexact matches as we found that there were some minor inconsistencies in how the municipalities were named in our dataset as opposed to their names in the ISTAT shape files. The result of the following chunk of code is that all the municipalities are assigned their regions and provinces.

```{r}
cleaned_housing <- stringdist_left_join(cleaned_housing, munic_2022,by = c("location" = "COMUNE"), distance_col = "distance",ignore_case = T) %>% 
  group_by(location) %>% slice_min(distance) %>%
  select(-geometry,-distance) %>% 
  left_join(., as.data.frame(reg_2022[,c("COD_REG","DEN_REG")])) %>% 
  select(-geometry, -COMUNE) %>% 
  left_join(., as.data.frame(prov_2022[,c("DEN_UTS", "COD_PROV")], by = "COD_PROV")) %>% 
  select(-geometry, -COD_REG, -COD_PROV) %>% 
  rename(., "region" = "DEN_REG", "province" = "DEN_UTS") %>% 
  relocate(c(region, province), .after=location)
```

To answer the first exploratory question, we aggregate our data on two levels: 1) regional and 2) provincial level by computing two aggregate statistics: 1) the mean housing price and 2) the variance in housing price on the two respective levels. This yields two datasets, one per aggregation level. To each, we attach geometric information needed for plotting and convert it to an `sf` object which is a requirement for plotting maps.

```{r price_by_reg}
price_by_reg <- cleaned_housing %>% group_by(region) %>% 
  summarize(mean = mean(price, na.rm=T), median = median(price, na.rm=T), variance = var(price, na.rm=T), mad = mad(price,na.rm=T)) %>% left_join(.,reg_2022, by = c("region" = "DEN_REG")) %>% st_as_sf()
```

```{r price_by_prov}
price_by_prov <- cleaned_housing %>% group_by(province) %>% 
  summarize(mean = mean(price, na.rm=T), median = median(price, na.rm=T), variance = var(price, na.rm=T), mad = mad(price, na.rm=T)) %>% left_join(.,prov_2022, by = c("province" = "DEN_PROV")) %>% st_as_sf()
```

### Plot

As the distribution of `price` is still quite skewed, we inspect the median housing price and the corresponding variance by region. 

```{r mean_variance_region, fig.cap="Median and Variance of price per region"}
p1 <- ggplot(price_by_reg) +
  geom_sf(aes(fill = median))+
  theme_minimal()

p2 <- ggplot(price_by_reg) +
  geom_sf(aes(fill = variance))+
  theme_minimal()

ggarrange(p1, p2,
          labels = c("median", "variance"),
          legend = "bottom")
```

**Price difference between high- and low-median groups**
We can show facet_wrap...
```{r groupdiff}
top2_med <- price_by_reg %>% slice_max(median, n = 2) %>% pull(region)
bottom2_med <- price_by_reg %>% slice_min(median, n = 2) %>% pull(region)
groups <- list(top2_med = top2_med, bottom2_med = bottom2_med)

p3 <- cleaned_housing %>% 
  filter(region %in% top2_med) %>% 
  ggplot(aes(x = price, group = region)) +
  geom_histogram() +
  facet_wrap(~region)

p4 <- cleaned_housing %>% 
  filter(region %in% bottom2_med) %>% 
  ggplot(aes(x = price, group = region)) +
  geom_histogram() +
  facet_wrap(~region)

ggarrange(p3, p4, nrow=2)

## OR WE CAN PUT ALL IN ONE PLOT SHOWING THE HIGH MEDIAN GROUP VS LOW MEDIAN GROUP
cleaned_housing %>% 
  filter(region %in% c(top2_med, bottom2_med)) %>% 
  mutate(grouping = case_when(region %in% top2_med ~ "high", TRUE ~ "low")) %>% 
  ggplot(aes(x = price, color = grouping, fill = grouping)) +
  geom_density(alpha=0.5) + theme_minimal()

```

### Conclusion


<!-- We inspect the mean housing price by region.  -->

<!-- ```{r} -->
<!-- p1 <- ggplot(price_by_reg) + -->
<!--   geom_sf(aes(fill = mean))+   -->
<!--   ggtitle("Mean House Price by Region") + -->
<!--   theme_minimal() -->
<!-- ``` -->


<!-- We inspect the average housing price by province.  -->

<!-- ```{r} -->
<!-- ggplot(price_by_prov) + -->
<!--   geom_sf(aes(fill = mean))+ -->
<!--   ggtitle("Mean House Price by Province") + -->
<!--   theme_minimal() -->
<!-- ``` -->



<!-- We inspect the median housing price by province.  -->

<!-- ```{r} -->
<!-- ggplot(price_by_prov) + -->
<!--   geom_sf(aes(fill = median))+ -->
<!--   ggtitle("Median House Price by Province") + -->
<!--   theme_minimal() -->
<!-- ``` -->


<!-- ## Question 2: Geographical Differences in Variance and Median Absolute Deviation of Housing Prices -->

<!-- ### Preparation -->

<!-- ### Plot -->

<!-- We inspect the housing price variance by region.  -->

<!-- ```{r} -->
<!-- ggplot(price_by_reg) + -->
<!--   geom_sf(aes(fill = variance))+ -->
<!--   ggtitle("House Price Variance by Region") + -->
<!--   theme_minimal() -->
<!-- ``` -->


<!-- We inspect the housing price variance by province.  -->

<!-- ```{r} -->
<!-- ggplot(price_by_prov) + -->
<!--   geom_sf(aes(fill = variance))+ -->
<!--   ggtitle("House Price Variance by Province") + -->
<!--   theme_minimal() -->
<!-- ``` -->
<!-- We inspect the median absolute deviation of housing price by region. -->

<!-- ```{r} -->
<!-- ggplot(price_by_reg) + -->
<!--   geom_sf(aes(fill = mad))+ -->
<!--   ggtitle("House Price Median Absolute Deviation by Region") + -->
<!--   theme_minimal() -->
<!-- ``` -->


<!-- We inspect the median absolute deviation of housing price by province. -->

<!-- ```{r} -->
<!-- ggplot(price_by_prov) + -->
<!--   geom_sf(aes(fill = mad))+ -->
<!--   ggtitle("House Price Median Absolute Deviation by Province") + -->
<!--   theme_minimal() -->
<!-- ``` -->

<!-- ### Conclusion -->



## Question 3: Missingness \label{ref:missingness}

For this exploratory research, we are interested which variables can predict house prices. However, from an initial inspection, it became clear that some potential predictors contain missing values. Additionally, the outcome itself includes missing values. 

Therefore, we are interesting to explore if the missingness of the predictors and the outcome variable: house prices are related. First, we investigated the correlation between the missingness indicator for price and the predictors. Second, we visually examined the relationship between the predictors' missingness indicators and the price densities. Lastly, we visually inspected the percentage of missingness per region. These results could provide us some indication of the missing data mechanism. Specifically, if missing completely at random (MCAR) is plausible to assume or not. 

```{r missingness, out.width="70%", fig.align='center', fig.cap="Distribution of housing price"}
# barplot to show the missingness per variable
cleaned_housing %>%
   is.na() %>% colMeans() %>% stack() %>% 
   ggplot(aes(x = reorder(ind, values), y=values)) +
   geom_bar(stat="identity", width = .2, fill = "black") + 
   geom_point() +
   theme_minimal() + 
   coord_flip() +
   labs(x = "Variable", y = "Missingness (%)")
```

### Results

```{r}
# missingness correlation between price and predictors
cleaned_housing %>%
   mutate(missing = ifelse(is.na(price), 1, 0)) %>% 
   ungroup() %>% 
   summarize(across(n_rooms:property_age, ~cor(as.numeric(.x), missing, 
      use = "pairwise.complete.obs"))) %>% t(.) %>% .[order(abs(.)),] %>% 
   round(2)
```

The missingness of price appears to be moderately correlation with the energy class. Further, the missingness of price seems to be weakly correlated to having a garden and heating, and the type of home heating system.

```{r missingness_density, warning=FALSE, out.width="70%", fig.align='center', fig.caption = "Density Plots for Price based on the Missing Indicator for A) Floor B) No. of Rooms C) No. of Bathrooms D) Square Metres"}
# function to create a density plot of price with missing indicator
missing_plots <- function(x) {
   plot <- cleaned_housing %>% ungroup() %>%
      mutate(missing = is.na(.[,x])) %>%
      ggplot(aes(x = log10(price), fill = missing)) + 
      geom_density(alpha = 0.5, color = NA) + 
      theme_minimal() + 
      theme(legend.position = "top") + 
      labs(x = expression(paste(Log["10"],"(Price)"), y = "Density")) + 
      scale_x_continuous(limits = c(2, 7)) 
   return(plot)
}

# multiple plots for floor, no. of rooms, no. of bathrooms, and meters squared
ggarrange(missing_plots("floor"), 
          missing_plots("n_rooms"),
          missing_plots("n_bathrooms"),
          missing_plots("mq"),
          labels = c("A", "B", "C", "D"),
          ncol = 2, nrow = 2)
```

The missingness of number of floors (\@ref(fig:missingness_density) A) and number of rooms (\@ref(fig:missingness_density) B) does not seem to be dependent on the observed price information. Whereas for the number of bathrooms (\@ref(fig:missingness_density) C) and the meters squared (\@ref(fig:missingness_density) D) missingness shows a different result, namely missingness tends to occur at higher house prices.

```{r missing_reg, fig.cap = "Missingness of Price per Region"}
## check missingness w.r.t regions
cleaned_housing %>% 
   mutate(na_ind = ifelse(is.na(price), 1, 0)) %>%
   group_by(region) %>%
   summarize(total_missing = sum(na_ind) / n()) %>%
   left_join(.,reg_2022, by = c("region" = "DEN_REG")) %>% 
   st_as_sf() %>%
   ggplot() +
      geom_sf(fill=NA) +
      geom_point(color = "coral1",
      aes(size = total_missing, geometry = geometry),
      stat = "sf_coordinates") +
      theme_void() + 
      theme(legend.position = "bottom")
```

Finally, figure \@ref(fig:missing_reg) shows that the proportion of missing data is not equal for each region. 

### Conclusion

We explored if the missingness of the predictors and the outcome variable: house prices are related. From our results it appears that it does. Hence, it is unlikely that the missingness mechanism is MCAR. Therefore, we include an multiple imputation procedure before the creation of the prediction model in the next section.


## Question 4: Relevant Predictors for Housing Price

As mentioned in the previous section, we will handle the missing data using a multiple imputation procedure. Subsequently, we are interested to find out which variables can predict house prices. For this purpose, we used two step-wise modeling strategies. The first strategy consists of a backward selection method based on the pooled estimates. The second strategy is a forward selection method applied to each imputed data set ($m=5$) and variables are selected in the final that appear the majority of the models. The models will be compared based on their included predictors, pooled coefficient of determination, and Bayesian information criterion (BIC).

### Preparation

```{r}
# fix seed for reproducibility
set.seed(1)

# reduced data set 
housing_sampled <- cleaned_housing %>% 
   # ungroup on location
   ungroup() %>%
   # sample 10000 records
   sample_n(10000) %>%
   # ignore location, and province information
   select(-location, -province)
```

```{r eval=TRUE, include=FALSE}
library(mice)

# create predictor matrix
pred <- housing_sampled %>% quickpred()

# multiple imputation procedure (m = 5)
imp <- mice(housing_sampled, m = 5, seed = 1, predictorMatrix = pred, print = TRUE)
```

```{r}
# convergence of the algorithm
plot(imp)

# plausibility of the imputed data
densityplot(imp, ~n_rooms + mq + floor + n_bathrooms + price, lwd = 2)
```

To reduce the computation time of the imputation model, we sampled 10000 records from the initial data set. Further, for the scope of this exploratory research, we limited ourselves to simple random sampling and disregarding location and province as predictors. Furthermore, we limited the diagnostics for the imputation procedure to the convergence of the algorithm and plausibility of the imputed data. There appeared to be no convergence issues and the imputed data appeared to be plausible with respect to the observed data.

### Analysis

```{r eval=TRUE, include=FALSE}
# model based on backward selection method based on the pooled estimates
model_1 <- with(imp, lm(price ~ region + n_rooms + mq + n_bathrooms +
   energy_class + heating + has_terrace + has_alarm +
   has_pool + has_elevator))

# pooled effect estimates 
summary(pool(model_1)) 

# pooled r-squared estimate 
pool.r.squared(model_1)
```

The model based on backward selection method based on the pooled estimates contains 10 predictors: region, number of rooms, squared meters, number of bathrooms, energy class, type of home heating system, and the home including a terrace, alarm, pool, or elevator. The predictors in the model explain 40 percent of the variability observed in the house price.

```{r message=FALSE, warning=FALSE}
# define the scope of which predictors
scope <- list(upper = ~ region + n_rooms + floor + mq + n_bathrooms + 
   energy_class + heating + has_garage + has_terrace + has_garden + has_balcony + 
   has_fireplace + has_alarm + has_air_conditioning + has_pool + has_parking + 
   has_elevator + is_furnished + property_age,
              lower = ~ 1)

# apply a forward selection method to each imputed data set
expr <- expression(f1 <- lm(price ~ 1),
                   f2 <- step(f1, scope = scope))
fit <- with(imp, expr)

# majority vote which predictors to include
formulas <- lapply(fit$analyses, formula)
terms <- lapply(formulas, terms)
votes <- unlist(lapply(terms, labels))
table(votes)

# model based on forward selection method applied to each imputed data set
model_2 <- with(imp, lm(price ~ energy_class + floor + has_alarm + has_elevator + 
   has_garden + has_pool + has_terrace + heating + mq + n_bathrooms + 
   n_rooms + property_age + region))

# pooled effect estimates 
summary(pool(model_2))

# pooled r-squared estimate 
pool.r.squared(model_2, adjusted = TRUE)
```

The model based on backward selection method based on the pooled estimates contains 13 predictors: region, number of rooms, number of floor, squared meters, number of bathrooms, energy class, type of home heating system, property age and the home including a elevator, alarm, garden, pool, or terrace. The predictors in the model explain 40 percent of the variability observed in the house price. The code for the second model is reused from Gerko Vinks' mice vignettes, which are [publicly available]("https://www.gerkovink.com/miceVignettes/").

```{r}
# derive the BIC value for each model
model_1_bic <- model_1$analyses %>% sapply(BIC)
model_2_bic <- model_2$analyses %>% sapply(BIC)

# compare the BIC value
sum(model_1_bic < model_2_bic)
model_2_bic - model_1_bic
```

To compare the models we used the BIC for each imputed data set. For all imputed data sets, the BIC favors model 1 over model 2. For all comparisons, the absolute difference in BIC score is at least 10 points. So, according to the BIC model 1 is preferred. This is congruent with the coefficient of determination results, considering adding three predictors: floor, property age, garden, did not yield a higher r-squared value. 

### Conclusion



# Overall Conclusion



# Appendix \label{ref:appendix}
Summary of the raw data using the my_skim function.
```{r}
my_skim(housing)
```

