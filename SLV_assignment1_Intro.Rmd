---
title: |
  \textbf{Exploratory Data Analysis on Housing Market in Italy} \vspace {1cm}
subtitle: |
  \Large Supervised Learning & Visualization \vspace {1cm}
  
  ![](img/italymap.png){width=2in}  
author: 
- Daniel Anadria
- Kyuri Park 
- Ernst-Paul Swens
- Emilia Löscher 
date: "October 3, 2022"
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    toc_depth: 1
    df_print: kable
    highlight: tango
  html_document:
    toc: true
    toc_float: true
    number_sections: true
geometry: "left = 2cm, right = 2cm, top = 2cm, bottom = 2cm"
linkcolor: NavyBlue
fontsize: 11pt
---
<style type="text/css">
@import url('https://fonts.googleapis.com/css2?family=Lato:wght@300;400&display=swap');

body{ /* Normal  */
  font-size: 13px;
  font-family: 'Lato', sans-serif;
  }
h1.title {
  font-size: 25px;
  color: DarkBlue;
  margin-bottom:5px;
}
.author{
  display: inline-block;
  padding: 5px;
}
h1 { /* Header 1 */
  font-size: 20px;
  font-weight: bold;
}
h2 { /* Header 2 */
  font-size: 15px;
  line-height: 1.6;
}
h3 { /* Header 3 */
  font-size: 14px;
  line-height: 1.6;
}
pre { /* Code block */
  font-size: 13px;
}
td {  /* Table  */
  font-size: 12px;
}
.subtitle p{
  font-size: 20px;
  font-weight: bold;
}
.author{
 font-size: 15px;
}
.date{
 font-size: 15px;
}
</style>
<hr>

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
               warning = FALSE,
               comment = NA)
```

# Introduction
\vspace{-0.5cm}
This is an exploratory data analysis of the Italian housing market in 2022. 
For context, Italy contains a total of 20 regions (*regioni*), 107 provinces (*province*) and 7,904 municipalities (*comuni*). In the present work, we pose several interesting research questions which can be answered by means of data visualization and predictive model building.

## The Dataset

Our dataset originates from [Kaggle](https://www.kaggle.com/datasets/tangelus/housing-data-in-italy-august-2022?resource=download). 
It contains information about the housing market in Italy in 2022.
The data were scraped from one of the most prominent housing sales websites in Italy during the month of *August 2022*. The data consist of more than 223,000 sales posts spread over 7,023 (89% coverage) Italian municipalities.
We do not have any information on the representativeness of our dataset. Hence, we advise caution when drawing inferences from our findings.

In order to plot the statistics of interest to maps of Italy, we use the regional and provincial shape files, which are obtained from the *Italian National Institute of Statistics* [(ISTAT)](https://www.istat.it/it/archivio/222527). 
These files contain the regional and provincial coding and geographical shape information, which can be used to cluster the [municipalities](https://en.wikipedia.org/wiki/Comune) in our `location` variable into their respective provinces and regions. 

For each housing sale post, the dataset contains the following variables:

| **Variable**          | **Description**                              |
| :-------------------- | :------------------------------------------- |
|`id`                   | ID of the sale                               |
|`timestamp`            | Timestamp consisting of 10 digits            |
|`location`             | Location on municipality level               |
|`title`                |  Short description of property               |
|`price`                |  Price in Euros                              |
|`n_rooms`              | Number of rooms                              |
|`floor`                | Floor                                        |
|`mq`                   |       Size in square meters                  |
|`n_bathrooms`          |   Number of bathrooms                        |
|`year_of_construction` | Year of construction                         |
|`availability`         | Availability of property                     |
|`energy_class`         | Energy class ranging from a+ to g            |
|`status`               |   Status of the property                     |
|`heating`              |    Type of heating                           |
|`has_garage`           | Garage present: yes (1), no (0)              |
|`has_terrace`          |   Terrace present: yes (1), no (0)           |
|`has_garden`           | Garden present: yes (1), no (0)              |
|`has_balcony`          | Balcony present: yes (1), no (0)             |
|`has_fireplace`        |  Fireplace present: yes (1), no (0)          |
|`has_alarm`            |  Alarm present: yes (1), no (0)              |
|`has_air_conditioning` | Air Conditioning present: yes (1), no (0)    |
|`has_pool`             | Pool present: yes (1), no (0)                |
|`has_parking`          | Parking present: yes (1), no (0)             |
|`has_elevator`         | Elevator present: yes (1), no (0)            |
|`is_furnished`         | Furniture present: yes (1), no (0)           |
Table: Description of Variables in the Italy Housing Dataset


# Preparation

In order to start our exploratory analysis, we first load relevant packages and import the dataset as well as the ISTAT shape files. 

## Load Packages & Import Data

```{r libraries+datasets, results='hide'}
## load packages
library(tidyverse) # for wrangling data
library(magrittr) # for using pipes
library(skimr) # for skimming data 
library(sf) # for spatial analysis
library(sp) # for spatial analysis
library(ggplot2) # for plotting
library(fuzzyjoin) # for joining on not-exact matches
library(ggpubr) # for arranging ggplots

## import Italy housing data
housing <- read.csv("data/housing_data_italy_august2022.csv", 
                    na.strings=c("","NA"), header = TRUE)
## import ISTAT shape files
# municipality
muni_2022 <- st_read("data/italy_shape_2022_files/Com01012022_g")[c("COD_REG",
                                                                    "COD_PROV", "COMUNE")]  
# province
prov_2022 <- st_read("data/italy_shape_2022_files/ProvCM01012022_g") 
# region
reg_2022 <- st_read("data/italy_shape_2022_files/Reg01012022_g")
```

# Exploratory Research Analyses

We focus on following the exploratory analyses:  
1. Exploring the missingness in the dataset.
2. Investigate whether there any geographical trends in the median housing prices and their absolute deviations on regional and/or provincial level?

# Data Cleaning
\vspace {-0.3cm}
***Note***: We base the following data cleaning on the summary of the raw dataset, which can be found in the *Appendix*.  

The original data consist of 223,409 rows (*sales*) and 25 columns (*variables*).  
Given our research questions, we exclude `id` (*ID of the sale*), `timestamp` (*timestamp of the sale*), and `title` (*description of the property*) as they are deemed irrelevant.
In addition, we exclude two columns that have only one unique value (`status` and `availibility`), as these are not variables but constants.

We observe that types of some variables are wrongly specified. We convert them to a correct type (e.g., `heating`: character$\rightarrow$factor, `has_xxx`: numeric$\rightarrow$factor, `is_furnished`: numeric$\rightarrow$factor).

Next we create a new variable `property_age` by subtracting the `year_of_construction` from 2022. In the original dataset, there are some unreasonable years of construction (e.g., 2209). While some properties may be sold before their construction is completed, we deem it unlikely for properties whose `year_of_construction` is more than 4 years later as of now. Thus, we filter out those with `year_of_construction` > 2026. 

The variable of our main interest `price` is highly skewed to the right given that the mean (239,939) is far off to the right of the median (135,000). We take a closer look at the distribution of the `price` with the help of a boxplot to examine the outliers (see *Figure 1*). 

```{r figure1, out.width="70%", fig.align='center', fig.show='hold',fig.cap="Boxplot of Housing Prices in Italy"}
## create our own theme that can be used throughout
My_theme = theme(
  axis.title.x = element_text(size = 16),
  axis.text.x = element_text(size = 15),
  axis.title.y = element_text(size = 16),
  axis.text.y = element_text(size = 15))

## boxplot of price
housing %>% 
ggplot(aes(x=price)) +
  geom_boxplot() + theme_minimal() +
  # add comma on the x-axis labels
  scale_x_continuous(labels=scales::label_comma(), 
                     # rotate the x-axis labels
                     guide = guide_axis(angle = 25)) +
  # apply our own theme specified above
  My_theme
```
From *Figure 1*, we observe that there are extreme outliers in `price`. Some housing prices in the dataset are exorbitant (e.g., over €2B). We decide to focus the scope of our analysis on the houses whose price is less than or equal to €1M, which are more likely to be affordable to an average Italian. The distribution of housing prices after filtering can be seen in *Figure 2*.

```{r figure2, out.width="70%", fig.align='center',fig.show='hold', fig.cap="Histogram and Density Plot of Housing Price After Filtering"}
## density plot of price (cleaned dataset)
housing %>% 
  # filter the price over a million
  filter(price <= 1e6 | is.na(price)) %>% 
  # create a ggplot
  ggplot(aes(price)) + 
  # add histogram 
  geom_histogram(aes(y=..density..), color = 1, fill="white") + 
  # add density line
  geom_density(lwd=0.5, color = 4, fill = 4, alpha = 0.2) + 
  # apply our theme
  theme_minimal() + My_theme
```
From *Figure 2*, we take that the distribution of housing prices after filtering appears a lot more ordinary. There is still a long right tail, but that is to be expected with housing prices in any country. The extreme outliers have been eliminated. From this plot, we also conclude that when working with housing price data, it is likely to be more informative to use centrality and spread measures that are robust to skewed data. For this reason, we will use the *median* and *median absolute deviation (MAD)* instead of the mean and variance in our exploration of the present dataset. 

```{r data_cleaning}
## cleaning up the housing data
cleaned_housing <- housing %>% 
  # only select variables that have more than one unique value
  select(where(~n_distinct(.) > 1)) %>% 
  # fix the data type (convert them to factor)
  mutate(across(c(starts_with("has"), is_furnished, heating, energy_class, n_rooms, 
                  n_bathrooms, location), factor)) %>%
  # filter out houses whose price is over a million (while keeping NAs)
  filter(price <= 1e6 | is.na(price), 
  # filter out houses whose construction year is more than 4 years later 
  # as of today (while keeping NAs)
         year_of_construction < 2026 | is.na(year_of_construction)) %>% 
  # create property age variable
  mutate(property_age = 2022 - as.numeric(year_of_construction)) %>% 
  # remove id, timestamp, title and year_of_construction
  select(-c(id, timestamp, title, year_of_construction)) 
```

## Data Summary

After data cleaning, we take a look at the summary statistics to get a better overview of our data.
We skim through our cleaned dataset using the `skimr` package.

```{r data_summary}
# settings: round up by 2 decimal places & disable scientific notation
options(digits = 3, scipen = 999) 
# specify skimming function
my_skim <- skim_with(character = sfl(whitespace=NULL, min = NULL, max = NULL),
                     factor = sfl(ordered = NULL),
                     numeric = sfl(p0 = NULL, p25=NULL, p50=NULL, p75=NULL,
                                   p100=NULL, hist=NULL, median = ~median(., na.rm=T), 
                                   min = ~min(., na.rm=T), max = ~max(., na.rm=T), 
                                   n_unique=n_unique))
# summary table
my_skim(cleaned_housing) 
```

From the output, we see that our cleaned dataset has 220,607 rows and 20 columns, 16 of which are factors, and 4 of which are numeric types. The output is presented in two tables for factor and numeric variables, separately. 

From the table of factor variables, we again see that `location` has 7023 unique values (i.e., municipalities).  Also, there are some missing values for `energy_class` and a lot of missing values for `n_rooms` and `n_bathrooms`.

From the table of numeric variables, we see that all numeric variables have some missing values. For about 18% of `price`, the variable of our main interest, is missing and we look into this more in detail when we address the 2nd question regarding the missingness in `price`.
***@ALL: Any other statistics interesting? mean, sd?.. something?***

# Exploratory Data Analysis
In the following we are performing the exploratory data analyses. First, we explore the missingness in the dataset. Afterwards, we explore trends in *house price* on the regional and provincial level. 

## Question 1: Exploring missingness in the dataset.
As we later want to analyze the data on the regional and provincial level, we also want to explore the missingness on these levels. Therefore, we aggregate the data from a municipality level to the regional and provincial level. This process is described in the following section. 

## Geographical Data Preparation 
At the beginning of the assignment, we loaded the *ISTAT* shape files. These files are useful for two reasons.
First, they contain the list of all Italian municipalities, their respective provinces and regions.
Therefore, we can use this data to append our original dataset with additional location indicators.
Second, they contain the shapes of Italy divided into provinces and regions. 
This is particularly useful for creating map plots using `ggplot2`.

Each sale in our dataset is assigned to one of 7023 municipalities. In order to create plots which visualize the differences in average housing prices across Italy, we assign each municipality to its corresponding province and region. We use the data from *ISTAT* to append the province and region information to every observed municipality in our dataset. 
We use fuzzy matching for inexact matches as we found that there were some minor inconsistencies in how the municipalities were named in our dataset as opposed to their names in the ISTAT shape files. The result of the following chunk of code is that all the municipalities are assigned their regions and provinces.

```{r prepgeo, cache=TRUE}
cleaned_housing <- stringdist_left_join(cleaned_housing, muni_2022,by = 
                                          c("location" = "COMUNE"), 
                                        distance_col = "distance", ignore_case = T)%>% 
  group_by(location) %>% slice_min(distance) %>%
  select(-geometry,-distance) %>% 
  left_join(., as.data.frame(reg_2022[,c("COD_REG","DEN_REG")])) %>% 
  select(-geometry, -COMUNE) %>% 
  left_join(., as.data.frame(prov_2022[,c("DEN_UTS", "COD_PROV")], by = "COD_PROV"))%>% 
  select(-geometry, -COD_REG, -COD_PROV) %>% 
  rename(., "region" = "DEN_REG", "province" = "DEN_UTS") %>% 
  relocate(c(region, province), .after=location)
```

To answer our first research question, we aggregate our data on two levels: 1) regional and 2) provincial level by computing two aggregated statistics: 1) the median housing price and 2) the median absolute deviation (MAD) in housing price on the two respective levels. This yields two sub-datasets, one per each level. To each, we attach geometric information needed for geographic plotting and convert it to an `sf` object which is a requirement for plotting maps.

```{r price_by_reg}
price_by_reg <- cleaned_housing %>% group_by(region) %>% 
  summarize(median = median(price, na.rm=T), mad = mad(price,na.rm=T)) %>% 
  left_join(.,reg_2022, by = c("region" = "DEN_REG")) %>% st_as_sf()
```

```{r price_by_prov}
price_by_prov <- cleaned_housing %>% group_by(province) %>% 
  summarize(mean = mean(price, na.rm=T), median = median(price, na.rm=T), 
            variance = var(price, na.rm=T), mad = mad(price, na.rm=T)) %>% 
  left_join(.,prov_2022, by = c("province" = "DEN_PROV")) %>% st_as_sf()
```

Having done this, we are ready to explore the missingness in the dataset.

First, we do so by calculating and plotting the proportion of missing values for all the variables in Figure \@ref(fig:missingness). 

```{r missingness, out.width="70%", fig.align='center', fig.cap="Distribution of housing price"}
# barplot to show the missingness per variable
cleaned_housing %>%
   is.na() %>% colMeans() %>% stack() %>% 
   ggplot(aes(x = reorder(ind, values), y=values)) +
   geom_bar(stat="identity", width = .2, fill = "black") + 
   geom_point() +
   theme_minimal() + 
   coord_flip() +
   labs(x = "Variable", y = "Missingness (%)")
```
The plot shows that the percentage of missing values lies above 30\% for the variable *floor* and above 25\% for the *number of rooms*. Furthermore, about 18\% of the *housing prices* are missing. Except for the *number of bathrooms* which has about 6\% values missing, for the remaining variables less than 3\% are missing, respectively. 

In the following, we explore the correlation of *price* and the other variables and summarize the findings in *Table XX*.
```{r}
cleaned_housing %>%
  # create missingness indicator of price
  mutate(na_ind = ifelse(is.na(price), 1, 0)) %>% 
  ungroup() %>% 
  # compute correlation
  summarize(across(n_rooms:property_age, ~cor(as.numeric(.x), na_ind, 
                                              use = "pairwise.complete.obs"))) %>% 
  # sort them in descending order based on their absolute values
  t(.) %>% .[order(abs(.), decreasing = TRUE),] %>% 
  # create a neat table
  knitr::kable(col.names = "correlation", caption = "Correlation between missingness 
               of price and other variables", align="c")
```
The missingness of `price` appears to be moderately correlated with the `energy_class` (*cor = -0.271*). Hence, we further check what the pattern of missingness in price across different energy class looks like.

```{r corrplots, fig.cap = "Missing values in price across different energy classes", out.width="70%", fig.align='center'}
## create plots for missingness in price vs energy class
cleaned_housing %>%
  # add price missingness indicator
  mutate(na_ind = ifelse(is.na(price), 1, 0)) %>% 
  # group by energy class
  group_by(energy_class) %>% 
  # sum up all the missingness in price per energy class
  summarize(n = sum(na_ind)) %>% 
  # create a ggplot for the sum of missingness
  ggplot(aes(x = energy_class, y = n)) +
  # apply our theme to the bar plot
  geom_col() + theme_minimal() + My_theme +
  # change the labels
  labs(x = "Energy Class", y = "Missingness in price")
```
*Figure XX* shows that there is higher missingness in price for houses that either have a good energy class of *a* or *a1*, or fall into the very inefficient energy class *g*. There is low missingness in *price* for the other energy classes and for houses for which *price* is missing. 

We also check the missingness in price across different regions to see if there are any patterns.
```{r, fig.cap = "Missingness of Price per Region", out.width="80%", fig.align='center'}
## check missingness in price w.r.t regions
cleaned_housing %>% 
  # add price missingness indicator
   mutate(na_ind = ifelse(is.na(price), 1, 0)) %>%
   group_by(region) %>%
  # get the total missingness proportion per region
   summarize(total_missing = sum(na_ind) / n()) %>%
  # add the spatial data
   left_join(.,reg_2022, by = c("region" = "DEN_REG")) %>% 
   st_as_sf() %>%
   ggplot() +
  # plot the italy map
      geom_sf(fill=NA) +
  # add scatter plots of missingness proportion per region
      geom_point(color = "coral1",
      aes(size = total_missing, geometry = geometry),
      stat = "sf_coordinates") +
  # remove unnecessary coordinates
      theme_void() + 
      theme(legend.position = "bottom")
```

*Figure 7* shows that the proportion of missing data in `price` is not equal across different regions. 

<!-- Therefore, we explored if the missingness of the predictors and the outcome variable *house prices* are related. First, we investigated the correlation between the missingness indicator for *price* and the predictors. Second, we visually examined the relationship between the predictors' missingness indicators and the *price* densities. Lastly, we visually inspected the percentage of missingness per region.   -->

Next, we examine the relationship between the predictors' missingness indicators and the *price* densities by plotting the density of price (on a log10-scale) split by whether or not the respective value for a given variable is missing or not. These results provide us with some indication of the missing data mechanism. Specifically, if missing completely at random (MCAR) is plausible to assume or not.
```{r missingness_density, warning=FALSE, out.width="70%", fig.align='center', fig.caption = "Density Plots for Price based on the Missing Indicator for A) Floor B) No. of Rooms C) No. of Bathrooms D) Square Metres"}
# function to create a density plot of price with missing indicator
missing_plots <- function(x) {
   plot <- cleaned_housing %>% ungroup() %>%
      mutate(missing = is.na(.[,x])) %>%
      ggplot(aes(x = log10(price), fill = missing)) + 
      geom_density(alpha = 0.5, color = NA) + 
      theme_minimal() + 
      theme(legend.position = "top") + 
      labs(x = expression(paste(Log["10"],"(Price)"), y = "Density")) + 
      scale_x_continuous(limits = c(2, 7)) 
   return(plot)
}

# multiple plots for floor, no. of rooms, no. of bathrooms, and meters squared
ggarrange(missing_plots("floor"), 
          missing_plots("n_rooms"),
          missing_plots("n_bathrooms"),
          missing_plots("mq"),
          labels = c("A Floor", "B # rooms", "C # bathrooms", "D $m^2$"),
          ncol = 2, nrow = 2)
```

The missingness of number of floors (\@ref(fig:missingness_density) A) and number of rooms (\@ref(fig:missingness_density) B) does not seem to be dependent on the observed price information. Whereas for the number of bathrooms (\@ref(fig:missingness_density) C) and the meters squared (\@ref(fig:missingness_density) D) missingness shows a different result, namely, missingness tends to occur at higher house prices.

### Intermediate Conclusion

We explored if the missingness of the predictors and the outcome variable *house prices* are related. From our results it appears that they are. Hence, it is unlikely that the missingness mechanism is MCAR. Therefore, we include a multiple imputation procedure before investigating geographical trends in the median and the MAD.

### Imputation

```{r}
# fix seed for reproducibility
set.seed(1)

# reduced dataset 
housing_sampled <- cleaned_housing %>% 
   # ungroup on location
   ungroup() %>%
   # sample 10000 records
   sample_n(10000) %>%
   # ignore location, and province information
   select(-location, -province)
```

```{r eval=TRUE, include=FALSE}
library(mice)

# create predictor matrix
pred <- housing_sampled %>% quickpred()

# multiple imputation procedure (m = 5)
imp <- mice(housing_sampled, m = 5, seed = 1, predictorMatrix = pred, print = TRUE)
```



Furthermore, we limited the diagnostics for the imputation procedure to the convergence of the algorithm and plausibility of the imputed data. There appeared to be no convergence issues and the imputed data appeared to be plausible with respect to the observed data (see Appendix).


***1st Question : SECTION CONCLUSION / DESCRIPTION***

## Question 2: Regional and Provincial Trends in the Median Housing Price and the Median Absolute Deviations in Italy
We use the imputed dataset to explore whether there is a geographical trend in the median and the median absolute deviation (MAD) *housing price* on a regional or provincial level. In order to do so, we plot the median and the MAD on the regional and the provincial level:
```{r median_mad_region}
plot_list1 <- list()
## median & mad of price per region 
plot_list1 <- map(
  c("median", "mad"),
  function(var) {
    ggplot(price_by_reg) +       
      # map each statistic
      geom_sf(aes(fill = .data[[var]])) +
      # void theme: remove all unncessary coordinates
      theme_void() +
      # color-scheme (color-blind friendly???)
      scale_fill_viridis_c(option = "E", direction = -1) +
      # lengthen the legend
      theme(legend.key.width= unit(2, 'cm'))
     }
  )
plot_list2 <- list()
## median & mad of price per province 
plot_list2 <- map(
  c("median", "mad"),
  function(var) {
    ggplot(price_by_prov) +
      # map each statistic
      geom_sf(aes(fill = .data[[var]])) +
      # void theme: remove all unncessary coordinates
      theme_void() +
      # color-scheme (color-blind friendly???)
      scale_fill_viridis_c(option = "E", direction = -1) +
      # lengthen the legend
      theme(legend.key.width= unit(2, 'cm'))
     }
  )
# combine the plot lists
plot_list <- c(plot_list1, plot_list2)
```
```{r fig.cap="Median of Price per Region (left) and Province (right)", out.width="80%", fig.align='center'}
## plot the median of price
ggarrange(plotlist = plot_list[c(1,3)], nrow = 1, ncol = 2, common.legend = TRUE, 
          legend = "bottom")
```
```{r fig.cap="MAD of Price per Region (left) and Province (right)", out.width="80%", fig.align='center'}
## plot the mad of price
ggarrange(plotlist = plot_list[c(2,4)], nrow = 1, ncol = 2, common.legend = TRUE, 
          legend = "bottom")
```

On the regional level, we see that the median for the region *Trentino-Alto Adige* (200 000€) are the highest, and the lowest for *Molise* (79 000€). We recognize a trend that the median price is lower for more Southern regions in Italy. The only exception from this is the region of *Piemonte* (99 000€) which has a lower median price than the surrounding regions in the North. Regarding the MAD, a measure of variability within a region, we see that it is highest for the regions with higher median prices. This is recognizable as the color patterns in the median plot and the MAD plot are very similar. 

On the provincial level, it can be seen that the high median of the *Trentino-Alto Adige* region is mainly due to the high median of 400 000€ in the province of *Bolzano*. As the other provinces in that region have lower median prices, the MAD in that region is comparably high. 
The opposite is the case within the Southern regions, here, the provinces that make up the region of *Calabria* for example, all have a low median price. Hence, the MAD for that region is low. 


Given that the overall geographical pattern for median and MAD of `price` correspond to each other, it is interesting to investigate further the possible differences in the distribution of `price` between high- and low-median regions.
```{r groupdiff, fig.cap="group differences in price distribution"}
# top 2 high median regions
top2_med <- price_by_reg %>% slice_max(median, n = 2) %>% pull(region)
# bottom 2 low median regions
bottom2_med <- price_by_reg %>% slice_min(median, n = 2) %>% pull(region)

# plot the histograms for each region in the high and low median groups
cleaned_housing %>% 
  # subset top two and bottom two countries
  filter(region %in% c(top2_med, bottom2_med)) %>%
  # group by the regions
  group_by(region) %>%  
  # create the grouping variable for coloring 
  mutate(grouping = ifelse(region %in% top2_med, "high median", "low median"),
         # get the median price for each region
         med_price = median(price, na.rm=T)) %>% 
  # create ggplot for price (coloring by groups)
  ggplot(aes(x = price, fill = grouping)) +
  geom_histogram() +
  # create a panel of plots per region
  theme_bw() + facet_wrap(~region) +
  # indicate the median price by a vertical line
  geom_vline(aes(xintercept = med_price, group=region), linetype="dashed") +
  # change legend title
  labs(fill = "high/low regions")  
```

***1nd Question : SECTION CONCLUSION / DESCRIPTION***
An interesting take-away from this figure is that all the densities for the *house price* are right skewed. This is reasonable for house prices as one would expect that there are more cheap and moderately priced houses and only few very expensive houses. Furthermore, it is apparent that there are most sells in the dataset from the *Toscana* region and there are only very few very expensive houses in the regions of *Calabria* and *Molise* as one would expect with those regions having a lower median.

### Conclusion

# Overall Conclusion
All things considered, we identified that there is quite some missingness present - especially for *house price* for which about 18\% of values are missing. We were successful in imputing those and the values of the other variables.
Using the imputed dataset, we found a trend in the median price from more expensive to cheaper when going from Northern to Southern in Italy. We also have shown that these higher medians on a regional level are due to a higher median on the province level and that in such regions where there is one province with a higher median of *house price*, the MAD is consequently higher too if the other provinces in that region do not have a high median, too. 


<!--  ## Question 3: What are the most important predicotrs of housing price in Italy?

Ultimately, we are interested in which variables can predict house prices. However, from an initial inspection, it became clear that some potential predictors contain missing values. Additionally, the outcome `price` itself includes missing values. 
***SO WE WILL FIRST check the missingness mechanism -> DO IMPUTATION  -> AND THEN BUILD A PREDICTION MODEL BASED ON THE IMPUTATION DATA SET*** 








### Prediction model

As mentioned in the previous section, we will handle the missing data using a multiple imputation procedure. Subsequently, we are interested to find out which variables can predict house prices. For this purpose, we used two step-wise modeling strategies. The first strategy consists of a backward selection method based on the pooled estimates. The second strategy is a forward selection method applied to each imputed dataset ($m=5$) and variables are selected in the final that appear the majority of the models. The models will be compared based on their included predictors, pooled coefficient of determination, and Bayesian information criterion (BIC).

```{r, eval=TRUE, include=FALSE}
# model based on backward selection method based on the pooled estimates
model_1 <- with(imp, lm(price ~ region + n_rooms + mq + n_bathrooms +
   energy_class + heating + has_terrace + has_alarm +
   has_pool + has_elevator))

# pooled effect estimates 
summary(pool(model_1)) 

# pooled r-squared estimate 
pool.r.squared(model_1)
```

The model based on backward selection method based on the pooled estimates contains 10 predictors: region, number of rooms, squared meters, number of bathrooms, energy class, type of home heating system, and the home including a terrace, alarm, pool, or elevator. The predictors in the model explain 40 percent of the variability observed in the house price.

```{r, results='hide', cache=TRUE}
# define the scope of which predictors
scope <- list(upper = ~ region + n_rooms + floor + mq + n_bathrooms + 
   energy_class + heating + has_garage + has_terrace + has_garden + has_balcony + 
   has_fireplace + has_alarm + has_air_conditioning + has_pool + has_parking + 
   has_elevator + is_furnished + property_age,
              lower = ~ 1)

# apply a forward selection method to each imputed dataset
expr <- expression(f1 <- lm(price ~ 1),
                   f2 <- step(f1, scope = scope))
fit <- with(imp, expr)

# majority vote which predictors to include
formulas <- lapply(fit$analyses, formula)
terms <- lapply(formulas, terms)
votes <- unlist(lapply(terms, labels))
table(votes)

# model based on forward selection method applied to each imputed dataset
model_2 <- with(imp, lm(price ~ energy_class + floor + has_alarm + has_elevator + 
   has_garden + has_pool + has_terrace + heating + mq + n_bathrooms + 
   n_rooms + property_age + region))

# pooled effect estimates 
summary(pool(model_2))

# pooled r-squared estimate 
pool.r.squared(model_2, adjusted = TRUE)
```

The model based on backward selection method based on the pooled estimates contains 13 predictors: region, number of rooms, number of floor, squared meters, number of bathrooms, energy class, type of home heating system, property age and the home including a elevator, alarm, garden, pool, or terrace. The predictors in the model explain 40 percent of the variability observed in the house price. The code for the second model is reused from Gerko Vinks' mice vignettes, which are [publicly available]("https://www.gerkovink.com/miceVignettes/").

```{r, cache=TRUE}
# derive the BIC value for each model
model_1_bic <- model_1$analyses %>% sapply(BIC)
model_2_bic <- model_2$analyses %>% sapply(BIC)

# compare the BIC value
sum(model_1_bic < model_2_bic)
model_2_bic - model_1_bic
```

To compare the models we used the BIC for each imputed dataset. For all imputed datasets, the BIC favors model 1 over model 2. For all comparisons, the absolute difference in BIC score is at least 10 points. So, according to the BIC model 1 is preferred. This is congruent with the coefficient of determination results, considering adding three predictors: floor, property age, garden, did not yield a higher r-squared value. 

### Conclusion
The following 10 variables were identified to be good predictors of *house price* in Italy in the present dataset: region, number of rooms, squared meters, number of bathrooms, energy class, type of home heating system, and whether the home has a terrace, alarm, pool or elevator.
With the help of the prediction model 40\% of the variability observed in the house price can be explained.

Consequently, the presence of a balcony, air conditioning, parking, or fireplace seem not to be as informative for the housing price which some people might assume. 

-->



# Appendix \label{ref:appendix}

## Summary of the raw data using the my_skim function.
```{r}
my_skim(housing)
```

## Convergence of the algorithm and plausability of the imputed dataset
```{r}
# convergence of the algorithm
plot(imp)

# plausibility of the imputed data
densityplot(imp, ~n_rooms + mq + floor + n_bathrooms + price, lwd = 2)
```
